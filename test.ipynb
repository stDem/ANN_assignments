{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Не найдена указанная процедура'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check cuda is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "NVIDIA GeForce MX130\n",
      "<torch.cuda.device object at 0x00000290444E6650>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.current_device())    # The ID of the current GPU.\n",
    "print(torch.cuda.get_device_name(id))  # The name of the specified GPU, where id is an integer.\n",
    "print(torch.cuda.device(id))           # The memory address of the specified GPU, where id is an integer.\n",
    "print(torch.cuda.device_count())       # The amount of GPUs that are accessible.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs=20\n",
    "batch_size=32\n",
    "\n",
    "input=3\n",
    "layer=[32, 64, 128]\n",
    "classes=4\n",
    "\n",
    "train_images_path = 'SportBalls\\Train\\images'\n",
    "test_images_path = 'SportBalls\\Test\\images'\n",
    "labels_path='SportBalls\\Train\\labels.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create training, test and validation datasets (split train dataset in train and val datasets to get an accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    img_name  label_ball_1  label_ball_2\n",
      "0  img_00000             2             3\n",
      "1  img_00001             2             2\n",
      "2  img_00002             1             0\n",
      "3  img_00003             0             0\n",
      "4  img_00004             2             2\n",
      "Index(['img_name', 'label_ball_1', 'label_ball_2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load labels without column names and specify them\n",
    "column_names = ['img_name', 'label_ball_1', 'label_ball_2']\n",
    "labels_df = pd.read_csv(labels_path, header=None, names=column_names)\n",
    "\n",
    "# Debug: print the first few rows and columns of the DataFrame\n",
    "print(labels_df.head())\n",
    "print(labels_df.columns)\n",
    "\n",
    "# Create binary labels for multi-label classification\n",
    "def create_binary_labels(df):\n",
    "    df['label_baseball'] = df.apply(lambda x: 1 if x['label_ball_1'] == 0 or x['label_ball_2'] == 0 else 0, axis=1)\n",
    "    df['label_basketball'] = df.apply(lambda x: 1 if x['label_ball_1'] == 1 or x['label_ball_2'] == 1 else 0, axis=1)\n",
    "    df['label_volleyball'] = df.apply(lambda x: 1 if x['label_ball_1'] == 2 or x['label_ball_2'] == 2 else 0, axis=1)\n",
    "    df['label_soccerball'] = df.apply(lambda x: 1 if x['label_ball_1'] == 3 or x['label_ball_2'] == 3 else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "labels_df = create_binary_labels(labels_df)\n",
    "\n",
    "class CreateDatasets(Dataset):\n",
    "    def __init__(self, img_dir, labels_df=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        self.img_names = sorted(os.listdir(img_dir))\n",
    "        if labels_df is not None:\n",
    "            self.labels = labels_df[['label_baseball', 'label_basketball', 'label_volleyball', 'label_soccerball']].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.labels_df is not None:\n",
    "            labels = self.labels[idx]\n",
    "            return image, torch.tensor(labels, dtype=torch.float32)\n",
    "        else:\n",
    "            return image, self.img_names[idx]\n",
    "        \n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = CreateDatasets(train_images_path, labels_df, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = CreateDatasets(test_images_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display random image with corresponding lables from train dataset (just to check the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def displayImage():\n",
    "    idx = random.randint(0, len(train_dataset) - 1)\n",
    "    image, labels = train_dataset[idx]\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    label_names = ['baseball', 'basketball', 'volleyball', 'soccerball']\n",
    "    label_str = ', '.join([label_names[i] for i, label in enumerate(labels) if label == 1])\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Labels: {label_str}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "displayImage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the model: conv, relu, linear, pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input, layer, classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input, layer[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(layer[0], layer[1], kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(layer[1] * layer[0] * layer[0], layer[2])\n",
    "        self.fc2 = nn.Linear(layer[2], classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, layer[1] * layer[0] * layer[0])\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = torch.sigmoid(self.fc2(x))                          # Using sigmoid since we need binary output for each class\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=65536, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(input, layer, classes).to(device)\n",
    "\n",
    "print(device)\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Loop: Setting up the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def train (model, trainloader, optimizer):\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        tot_train_loss = 0 \n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            log_ps = model(images)\n",
    "            loss = loss_func(log_ps, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tot_train_loss += loss.item()\n",
    "           \n",
    "        # else:\n",
    "        #     # Turn off gradients for validation to save memory and speed up computations\n",
    "        #     with torch.no_grad():\n",
    "        #         model.eval()\n",
    "        #         correct = 0\n",
    "        #         total = 0\n",
    "        #         with torch.no_grad():\n",
    "        #             for i, (images, labels) in enumerate(trainloader):\n",
    "        #                 if i == 10: break\n",
    "        #                 images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        #                 outputs = model(images)\n",
    "        #                 predicted = (outputs > 0.5).float()\n",
    "        #                 total += labels.size(0) * labels.size(1)\n",
    "        #                 correct += (predicted == labels).sum().item()\n",
    "        #     model.train()\n",
    "               \n",
    "        #     train_loss = tot_train_loss / len(trainloader.dataset)\n",
    "        #     accuracy = 100 * correct / total\n",
    "          \n",
    "            \n",
    "            # print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "            # \"Loss {:.3f}.. \".format(train_loss),\n",
    "            # \"Accuracy {:.3f}\".format(accuracy))\n",
    "        print(f'Epoch [{e+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# # Define loss function and optimizers\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.7040\n",
      "Epoch [2/10], Loss: 1.8717\n",
      "Epoch [3/10], Loss: 1.7538\n",
      "Epoch [4/10], Loss: 1.7299\n",
      "Epoch [5/10], Loss: 1.7825\n",
      "Epoch [6/10], Loss: 1.7631\n",
      "Epoch [7/10], Loss: 1.6561\n",
      "Epoch [8/10], Loss: 1.7372\n",
      "Epoch [9/10], Loss: 1.8138\n",
      "Epoch [10/10], Loss: 1.7670\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation: Estimating the model's accuracy: \n",
    "- Estimating each classes accuracy and overall model's accuracy.\n",
    "- Creating csv file for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0282\n",
      "Accuracy for label 0: 0.5620\n",
      "Accuracy for label 1: 0.6085\n",
      "Accuracy for label 2: 0.5580\n",
      "Accuracy for label 3: 0.8510\n",
      "Overall Accuracy: 0.6449\n"
     ]
    }
   ],
   "source": [
    "def evaluateModel(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    \n",
    "    accuracies = {}\n",
    "    for i in range(4):\n",
    "        accuracies[i] = accuracy_score(all_labels[:, i], all_preds[:, i])\n",
    "\n",
    "    overall_accuracy = np.mean(list(accuracies.values()))\n",
    "    \n",
    "    return val_loss, accuracies, overall_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model on validation set\n",
    "val_loss, accuracies, overall_accuracy = evaluateModel(model, val_loader, loss_func)\n",
    "print(f'Validation Loss: {val_loss:.4f}')\n",
    "with open('accuracy.csv', 'w') as f:\n",
    "    for label, acc in accuracies.items():\n",
    "        print(f'Accuracy for label {label}: {acc:.4f}')\n",
    "        f.write(f'{label},{acc:.4f}\\n')\n",
    "    \n",
    "    print(f'Overall Accuracy: {overall_accuracy:.4f}')\n",
    "    f.write(f'All,{overall_accuracy:.4f}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating predictions for the test data and creating csv file for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_predictions = []\n",
    "test_image_names = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, img_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        predicted = (outputs > 0.5).int().cpu().numpy()     # choose classes only where sigmoid > 0.5\n",
    "        test_predictions.extend(predicted)\n",
    "        test_image_names.extend(img_names)\n",
    "\n",
    "# Save predictions to CSV\n",
    "preds_df = pd.DataFrame(test_predictions, columns=['baseball', 'basketball', 'volleyball', 'soccerball'])\n",
    "preds_df.insert(0, 'img_name', test_image_names)\n",
    "preds_df.to_csv('preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTPUTS:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
