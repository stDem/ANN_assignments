{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Не найдена указанная процедура'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 10000\n",
      "Number of test examples: 100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Custom dataset class with labels\n",
    "class SportBallsDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data_info = self.load_data_info()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data_info.iloc[idx, 0] + '.png')  # Append '.png'\n",
    "        if not os.path.exists(img_name):\n",
    "            print(f\"File not found: {img_name}\")\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = int(self.data_info.iloc[idx, 1])  # Ensure label is an integer\n",
    "        label = torch.tensor(label, dtype=torch.long)  # Convert to tensor\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def load_data_info(self):\n",
    "        labels_path = os.path.join(self.root_dir, 'labels.csv')\n",
    "        data_info = pd.read_csv(labels_path, header=None)\n",
    "        return data_info\n",
    "\n",
    "# Transforms for resizing and normalization\n",
    "transform = ToTensor()\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SportBallsDataset(root_dir='Sportballs/Train/', transform=transform)\n",
    "test_dataset = SportBallsDataset(root_dir='Sportballs/Test/', transform=transform)\n",
    "\n",
    "# Example usage of the datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Print the length of the datasets\n",
    "print(f\"Number of training examples: {len(train_dataset)}\")\n",
    "print(f\"Number of test examples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0188\n",
      "Epoch [2/5], Loss: 0.0123\n",
      "Epoch [3/5], Loss: 0.0134\n",
      "Epoch [4/5], Loss: 0.0152\n",
      "Epoch [5/5], Loss: 0.0159\n",
      "Test Reconstruction Loss: 0.0129\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32 * 32 * 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        x = x.view(x.size(0), 3, 32, 32)\n",
    "        return x\n",
    "\n",
    "# Instantiate and train the autoencoder\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test and calculate reconstruction loss\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Reconstruction Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 9641.1221\n",
      "Epoch [2/5], Loss: 8153.7861\n",
      "Epoch [3/5], Loss: 8372.4766\n",
      "Epoch [4/5], Loss: 8220.1201\n",
      "Epoch [5/5], Loss: 8310.2217\n",
      "VAE Test Reconstruction Loss: 519.3874\n"
     ]
    }
   ],
   "source": [
    "# Variational Autoencoder model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 4)  # 2 for mean and 2 for log variance\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32 * 32 * 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = h[:, :2], h[:, 2:]\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x = self.decoder(z)\n",
    "        x = x.view(x.size(0), 3, 32, 32)\n",
    "        return x, mu, logvar\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# Instantiate and train the VAE\n",
    "vae_model = VAE().to(device)\n",
    "vae_optimizer = optim.Adam(vae_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop for VAE\n",
    "for epoch in range(num_epochs):\n",
    "    vae_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        recon_images, mu, logvar = vae_model(images)\n",
    "        loss = vae_loss(recon_images, images, mu, logvar)\n",
    "        vae_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        vae_optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test and calculate reconstruction loss for VAE\n",
    "vae_model.eval()\n",
    "vae_test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        recon_images, mu, logvar = vae_model(images)\n",
    "        loss = vae_loss(recon_images, images, mu, logvar)\n",
    "        vae_test_loss += loss.item()\n",
    "\n",
    "vae_test_loss /= len(test_loader.dataset)\n",
    "print(f'VAE Test Reconstruction Loss: {vae_test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Accuracy: 0.2400\n",
      "VAE Accuracy: 0.2200\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            z = model.encoder(images.view(images.size(0), -1))\n",
    "            # recon_images = model.decoder(z)\n",
    "            _, predicted = torch.max(z.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Calculate accuracy for Autoencoder\n",
    "ae_accuracy = compute_accuracy(model, test_loader)\n",
    "print(f'Autoencoder Accuracy: {ae_accuracy:.4f}')\n",
    "\n",
    "# Calculate accuracy for VAE\n",
    "vae_accuracy = compute_accuracy(vae_model, test_loader)\n",
    "print(f'VAE Accuracy: {vae_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
